{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score \n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense \n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.config import LABEL_MAP, DATA_LEN, DATA_PATH, NUM_EXAMPLES, SEQUENCE_LENGTH, ACTIONS, TEST_SPLIT, NUM_EPOCHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data from Data Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop throuh each action folder, collect the example data and the appropraite label (enusre data has been created)\n",
    "\n",
    "examples, labels = [], []\n",
    "for action in ACTIONS: \n",
    "    for sequence in range(NUM_EXAMPLES):\n",
    "        \n",
    "        # load in all numpy data for a given example \n",
    "        window = []\n",
    "        for frame in range(SEQUENCE_LENGTH):\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame)))\n",
    "            window.append(res)\n",
    "        \n",
    "        # for current example, add all data for that sequence and appropraite label \n",
    "        examples.append(window)\n",
    "        labels.append(LABEL_MAP[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data into appropraite format\n",
    "X, y = np.array(examples), to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our data into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SPLIT) # 5% to test and 95% to train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# web app that allows you to see training\n",
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir Logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model architecture \n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape = (SEQUENCE_LENGTH, DATA_LEN))) # to stack LSTMs return_sequences needs to be True, the next layer will recieve the \"history\"\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(ACTIONS.shape[0], activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 30, 64)            442112    \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 30, 128)           98816     \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 596675 (2.28 MB)\n",
      "Trainable params: 596675 (2.28 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model and Save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "3/3 [==============================] - 5s 134ms/step - loss: 1.0962 - categorical_accuracy: 0.2353\n",
      "Epoch 2/250\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 1.0856 - categorical_accuracy: 0.3647\n",
      "Epoch 3/250\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 1.0722 - categorical_accuracy: 0.3529\n",
      "Epoch 4/250\n",
      "3/3 [==============================] - 0s 163ms/step - loss: 1.0555 - categorical_accuracy: 0.3529\n",
      "Epoch 5/250\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 1.0375 - categorical_accuracy: 0.3529\n",
      "Epoch 6/250\n",
      "3/3 [==============================] - 1s 162ms/step - loss: 1.0040 - categorical_accuracy: 0.4706\n",
      "Epoch 7/250\n",
      "3/3 [==============================] - 1s 172ms/step - loss: 0.9315 - categorical_accuracy: 0.5412\n",
      "Epoch 8/250\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.8625 - categorical_accuracy: 0.5882\n",
      "Epoch 9/250\n",
      "3/3 [==============================] - 0s 162ms/step - loss: 0.7479 - categorical_accuracy: 0.6118\n",
      "Epoch 10/250\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.7039 - categorical_accuracy: 0.6471\n",
      "Epoch 11/250\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 0.6128 - categorical_accuracy: 0.7294\n",
      "Epoch 12/250\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.4760 - categorical_accuracy: 0.8471\n",
      "Epoch 13/250\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.3782 - categorical_accuracy: 0.8471\n",
      "Epoch 14/250\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.3402 - categorical_accuracy: 0.8824\n",
      "Epoch 15/250\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.2870 - categorical_accuracy: 0.9176\n",
      "Epoch 16/250\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.2741 - categorical_accuracy: 0.9059\n",
      "Epoch 17/250\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2676 - categorical_accuracy: 0.8588\n",
      "Epoch 18/250\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.2319 - categorical_accuracy: 0.9412\n",
      "Epoch 19/250\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.1498 - categorical_accuracy: 0.9765\n",
      "Epoch 20/250\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.1433 - categorical_accuracy: 0.9647\n",
      "Epoch 21/250\n",
      "3/3 [==============================] - 1s 140ms/step - loss: 0.0826 - categorical_accuracy: 0.9882\n",
      "Epoch 22/250\n",
      "3/3 [==============================] - 0s 173ms/step - loss: 0.1657 - categorical_accuracy: 0.9412\n",
      "Epoch 23/250\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 0.1562 - categorical_accuracy: 0.9765\n",
      "Epoch 24/250\n",
      "3/3 [==============================] - 1s 155ms/step - loss: 0.3911 - categorical_accuracy: 0.8000\n",
      "Epoch 25/250\n",
      "3/3 [==============================] - 1s 189ms/step - loss: 0.3141 - categorical_accuracy: 0.8235\n",
      "Epoch 26/250\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.3332 - categorical_accuracy: 0.8471\n",
      "Epoch 27/250\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.3805 - categorical_accuracy: 0.8118\n",
      "Epoch 28/250\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.3482 - categorical_accuracy: 0.8706\n",
      "Epoch 29/250\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.3550 - categorical_accuracy: 0.8118\n",
      "Epoch 30/250\n",
      "3/3 [==============================] - 1s 174ms/step - loss: 0.3625 - categorical_accuracy: 0.9059\n",
      "Epoch 31/250\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 0.2629 - categorical_accuracy: 0.9412\n",
      "Epoch 32/250\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.1826 - categorical_accuracy: 0.9529\n",
      "Epoch 33/250\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.1010 - categorical_accuracy: 0.9647\n",
      "Epoch 34/250\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.1803 - categorical_accuracy: 0.9412\n",
      "Epoch 35/250\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1085 - categorical_accuracy: 0.9765\n",
      "Epoch 36/250\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1111 - categorical_accuracy: 0.9765\n",
      "Epoch 37/250\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0642 - categorical_accuracy: 0.9882\n",
      "Epoch 38/250\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0554 - categorical_accuracy: 0.9882\n",
      "Epoch 39/250\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0394 - categorical_accuracy: 0.9882\n",
      "Epoch 40/250\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0316 - categorical_accuracy: 0.9882\n",
      "Epoch 41/250\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.4257 - categorical_accuracy: 0.8941\n",
      "Epoch 42/250\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 1.9393 - categorical_accuracy: 0.6588\n",
      "Epoch 43/250\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 1.5060 - categorical_accuracy: 0.4706\n",
      "Epoch 44/250\n",
      "3/3 [==============================] - 1s 195ms/step - loss: 0.9427 - categorical_accuracy: 0.4588\n",
      "Epoch 45/250\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.9254 - categorical_accuracy: 0.5765\n",
      "Epoch 46/250\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.8322 - categorical_accuracy: 0.5882\n",
      "Epoch 47/250\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.8905 - categorical_accuracy: 0.5529\n",
      "Epoch 48/250\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.8478 - categorical_accuracy: 0.5882\n",
      "Epoch 49/250\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.7850 - categorical_accuracy: 0.6000\n",
      "Epoch 50/250\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.7170 - categorical_accuracy: 0.6000\n",
      "Epoch 51/250\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.6461 - categorical_accuracy: 0.5882\n",
      "Epoch 52/250\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.5771 - categorical_accuracy: 0.7294\n",
      "Epoch 53/250\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.4695 - categorical_accuracy: 0.8118\n",
      "Epoch 54/250\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.4200 - categorical_accuracy: 0.7765\n",
      "Epoch 55/250\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.4193 - categorical_accuracy: 0.7412\n",
      "Epoch 56/250\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.5757 - categorical_accuracy: 0.6941\n",
      "Epoch 57/250\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.5402 - categorical_accuracy: 0.7412\n",
      "Epoch 58/250\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3600 - categorical_accuracy: 0.8118\n",
      "Epoch 59/250\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.3413 - categorical_accuracy: 0.8235\n",
      "Epoch 60/250\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.3239 - categorical_accuracy: 0.8588\n",
      "Epoch 61/250\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.3012 - categorical_accuracy: 0.8941\n",
      "Epoch 62/250\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.2856 - categorical_accuracy: 0.8941\n",
      "Epoch 63/250\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2628 - categorical_accuracy: 0.9176\n",
      "Epoch 64/250\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2548 - categorical_accuracy: 0.9294\n",
      "Epoch 65/250\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.2374 - categorical_accuracy: 0.9059\n",
      "Epoch 66/250\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.2178 - categorical_accuracy: 0.9176\n",
      "Epoch 67/250\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1951 - categorical_accuracy: 0.9412\n",
      "Epoch 68/250\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.1936 - categorical_accuracy: 0.9294\n",
      "Epoch 69/250\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.1670 - categorical_accuracy: 0.9294\n",
      "Epoch 70/250\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1512 - categorical_accuracy: 0.9294\n",
      "Epoch 71/250\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1450 - categorical_accuracy: 0.9294\n",
      "Epoch 72/250\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1345 - categorical_accuracy: 0.9529\n",
      "Epoch 73/250\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1164 - categorical_accuracy: 0.9647\n",
      "Epoch 74/250\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1031 - categorical_accuracy: 0.9647\n",
      "Epoch 75/250\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0828 - categorical_accuracy: 0.9647\n",
      "Epoch 76/250\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0848 - categorical_accuracy: 0.9647\n",
      "Epoch 77/250\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0791 - categorical_accuracy: 0.9529\n",
      "Epoch 78/250\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0640 - categorical_accuracy: 0.9882\n",
      "Epoch 79/250\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0730 - categorical_accuracy: 0.9647\n",
      "Epoch 80/250\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 2.7959 - categorical_accuracy: 0.8353\n",
      "Epoch 81/250\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 5.2712 - categorical_accuracy: 0.4353\n",
      "Epoch 82/250\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 3.3070 - categorical_accuracy: 0.4353\n",
      "Epoch 83/250\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 6.5847 - categorical_accuracy: 0.4000\n",
      "Epoch 84/250\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 4.7851 - categorical_accuracy: 0.4118\n",
      "Epoch 85/250\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 3.0877 - categorical_accuracy: 0.4353\n",
      "Epoch 86/250\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 2.1196 - categorical_accuracy: 0.5176\n",
      "Epoch 87/250\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 1.9342 - categorical_accuracy: 0.4824\n",
      "Epoch 88/250\n",
      "3/3 [==============================] - 0s 137ms/step - loss: 1.4686 - categorical_accuracy: 0.4353\n",
      "Epoch 89/250\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 1.1406 - categorical_accuracy: 0.4824\n",
      "Epoch 90/250\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.9564 - categorical_accuracy: 0.5294\n",
      "Epoch 91/250\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.8925 - categorical_accuracy: 0.4941\n",
      "Epoch 92/250\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.7523 - categorical_accuracy: 0.6471\n",
      "Epoch 93/250\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.6419 - categorical_accuracy: 0.7294\n",
      "Epoch 94/250\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.5694 - categorical_accuracy: 0.8706\n",
      "Epoch 95/250\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.4996 - categorical_accuracy: 0.9059\n",
      "Epoch 96/250\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.4282 - categorical_accuracy: 0.8941\n",
      "Epoch 97/250\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.3905 - categorical_accuracy: 0.9059\n",
      "Epoch 98/250\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3624 - categorical_accuracy: 0.8941\n",
      "Epoch 99/250\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.3738 - categorical_accuracy: 0.8706\n",
      "Epoch 100/250\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3755 - categorical_accuracy: 0.8941\n",
      "Epoch 101/250\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.3165 - categorical_accuracy: 0.9059\n",
      "Epoch 102/250\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.3287 - categorical_accuracy: 0.8941\n",
      "Epoch 103/250\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2997 - categorical_accuracy: 0.9059\n",
      "Epoch 104/250\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2694 - categorical_accuracy: 0.9176\n",
      "Epoch 105/250\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.2534 - categorical_accuracy: 0.9294\n",
      "Epoch 106/250\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.2261 - categorical_accuracy: 0.9294\n",
      "Epoch 107/250\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.2177 - categorical_accuracy: 0.9412\n",
      "Epoch 108/250\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1966 - categorical_accuracy: 0.9529\n",
      "Epoch 109/250\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1841 - categorical_accuracy: 0.9294\n",
      "Epoch 110/250\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.2110 - categorical_accuracy: 0.9412\n",
      "Epoch 111/250\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1679 - categorical_accuracy: 0.9647\n",
      "Epoch 112/250\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1364 - categorical_accuracy: 0.9647\n",
      "Epoch 113/250\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.1332 - categorical_accuracy: 0.9647\n",
      "Epoch 114/250\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1141 - categorical_accuracy: 0.9765\n",
      "Epoch 115/250\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1338 - categorical_accuracy: 0.9529\n",
      "Epoch 116/250\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0889 - categorical_accuracy: 0.9765\n",
      "Epoch 117/250\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.1060 - categorical_accuracy: 0.9529\n",
      "Epoch 118/250\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.1118 - categorical_accuracy: 0.9765\n",
      "Epoch 119/250\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1438 - categorical_accuracy: 0.9647\n",
      "Epoch 120/250\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0969 - categorical_accuracy: 0.9765\n",
      "Epoch 121/250\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0668 - categorical_accuracy: 0.9882\n",
      "Epoch 122/250\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0988 - categorical_accuracy: 0.9647\n",
      "Epoch 123/250\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0826 - categorical_accuracy: 0.9882\n",
      "Epoch 124/250\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0462 - categorical_accuracy: 1.0000\n",
      "Epoch 125/250\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0776 - categorical_accuracy: 0.9765\n",
      "Epoch 126/250\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0313 - categorical_accuracy: 1.0000\n",
      "Epoch 127/250\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0294 - categorical_accuracy: 1.0000\n",
      "Epoch 128/250\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0300 - categorical_accuracy: 1.0000\n",
      "Epoch 129/250\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0190 - categorical_accuracy: 1.0000\n",
      "Epoch 130/250\n",
      "3/3 [==============================] - 0s 182ms/step - loss: 0.0147 - categorical_accuracy: 1.0000\n",
      "Epoch 131/250\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0139 - categorical_accuracy: 1.0000\n",
      "Epoch 132/250\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0115 - categorical_accuracy: 1.0000\n",
      "Epoch 133/250\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0119 - categorical_accuracy: 1.0000\n",
      "Epoch 134/250\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0095 - categorical_accuracy: 1.0000\n",
      "Epoch 135/250\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0055 - categorical_accuracy: 1.0000\n",
      "Epoch 136/250\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0073 - categorical_accuracy: 1.0000\n",
      "Epoch 137/250\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0045 - categorical_accuracy: 1.0000\n",
      "Epoch 138/250\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0053 - categorical_accuracy: 1.0000\n",
      "Epoch 139/250\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0040 - categorical_accuracy: 1.0000\n",
      "Epoch 140/250\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0040 - categorical_accuracy: 1.0000\n",
      "Epoch 141/250\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0032 - categorical_accuracy: 1.0000\n",
      "Epoch 142/250\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0030 - categorical_accuracy: 1.0000\n",
      "Epoch 143/250\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0024 - categorical_accuracy: 1.0000\n",
      "Epoch 144/250\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0022 - categorical_accuracy: 1.0000\n",
      "Epoch 145/250\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0021 - categorical_accuracy: 1.0000\n",
      "Epoch 146/250\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0022 - categorical_accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtb_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mikea\\Gesture_Recognition\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Mikea\\Gesture_Recognition\\lib\\site-packages\\keras\\src\\engine\\training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1740\u001b[0m ):\n\u001b[0;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Mikea\\Gesture_Recognition\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Mikea\\Gesture_Recognition\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Mikea\\Gesture_Recognition\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Mikea\\Gesture_Recognition\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    146\u001b[0m   (concrete_function,\n\u001b[0;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Mikea\\Gesture_Recognition\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs)\u001b[0m\n\u001b[0;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1351\u001b[0m     args,\n\u001b[0;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1353\u001b[0m     executing_eagerly)\n\u001b[0;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Mikea\\Gesture_Recognition\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[1;32mc:\\Users\\Mikea\\Gesture_Recognition\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1472\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Mikea\\Gesture_Recognition\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=NUM_EPOCHS, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model, you can name it whatever you want\n",
    "model.save('Models/gesture.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 650ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model.predict(X_test)\n",
    "ytrue = np.argmax(y_test, axis=1).tolist()\n",
    "yhat = np.argmax(yhat, axis=1).tolist()\n",
    "\n",
    "accuracy_score(ytrue, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2, 0],\n",
       "        [1, 2]],\n",
       "\n",
       "       [[2, 1],\n",
       "        [0, 2]]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilabel_confusion_matrix(ytrue, yhat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Gesture_Recognition",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
